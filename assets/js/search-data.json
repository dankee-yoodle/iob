{
  
    
        "post0": {
            "title": "Actual Nhl Markov Chain Paper",
            "content": "Markov Counting Process Description of a Sports League Applied to the National Hockey League . Abstract . This note develops a Markov Counting Processes (MCP) formalism for describing the evolution of scoring totals and scoring rates of sports teams playing in leagues with discrete-scoring rules, then applies the Poisson distribution to the formalism to derive a formula for the probability a National Hockey League (NHL) team transitions to (v) goals-for-per-game (GFg) at (n + m) games from (u) GFg at (n) games. Using the last 10 NHL seasons of scoring outcomes taken from Hockeyreference.com, transition probability predictions were calculated and compared to the derived MCP transition probability predictions with a linear regression. The resulting fit parameters with 95% confidence interval were [slope, intercept] = [0.994( pm)0.071, 0.032( pm)0.034], the r-squared value was .887, and the residuals were approximately normally distributed with a mean of approximately zero. The fit parameters, degree of correlation, and residual characteristics are interpreted as implying that that the derived MCP transition probabilities are equal to the NHL data transition probabilities plus noise resulting from limited data and estimations made in the model, suggesting that modeling the NHL as a set of Poisson Markov Counting Processes is justified. . Introduction | Applications of statistics to sports leagues are often efforts to inform predictions of outcomes of future league matchups. These efforts typically fit model parameters to past league matchup outcomes, finding strength estimates for each team that, under the chosen model‚Äôs assumptions, maximize the likelihood of having observed those past league matchup outcomes. Once the most probable team strengths are determined, the probability one team beats another can be estimated using a function of the two team‚Äôs strengths, and the estimating party can use the estimated probability to inform a prediction. . These team strengths are, at a basic level, reflections of team scoring rates ‚Äì the more scores a team earns per game and the less scores a team allows per game, the stronger the team. Despite that fact, there seems to have been little theoretical work done to describe the evolution of team scoring rates over the course of a season. The question representing the knowledge gap this paper aims fill is therefore, ‚ÄúIf a team has scoring rate (u) at (n) games into its season, what is the probability it will have scoring rate (v) at (n + m) games into its season?‚Äù . Section two begins to answer the representative question by introducing the MCP representation of a sports team, defining formalism for representing the probability of observing every possible season scoring total outcome for a team, and presenting actual NHL season scoring total outcomes as example MCP realizations. Section three extends the formalism to define a Markov chain (MC) representation of team season scoring rate outcomes, then presents actual NHL season scoring rate outcomes as example MC realizations. Section four specifies Poisson Counting Processes (PCPs) as approximate representations of NHL teams, then presents the Poisson version of the developed formalism. Section five describes the method used to compare MC scoring rate predictions and NHL data predictions for various parameter sets ((u,v,n,m)), then discusses the results. At the end, I provide derivations for starred equations. . Season Scoring as a Markov Counting Process . A time-domain Counting Process (CP) counts the number of events that occur during a period of time. The count, (C left( t right),) defined as the total number of events that have occurred up until time (t), is non-decreasing and takes only integer values. The state of the process at time (t) is (C left( t right),) and the state space the process exists in is C(t)‚Äôs range. Consider, as an example, repeatedly rolling a regular die. The sum of the values of the roll outcomes can be considered a discrete CP: C(1) ‚Äì the count after the first roll ‚Äì would be a random draw from Uniform(1,6), the Uniform distribution that can take values between one and six; C(2) would be the sum of two random draws from Uniform(1,6); and C(t) would be the sum of (t) random draws from Uniform(1,6). The state space the CP exists in would be the set of integers between 1*t and 6*t, because those are the smallest and the largest possible outcomes for a single roll, respectively. Because each roll of the die is an independent event, the probability C(t+1) takes some value depends only on C(t), and the die-rolling CP can be considered Markovian ‚Äì a Markov Counting Process. . In many popular sports such as Football, Soccer, Basketball, Baseball, and Hockey, only a positive integer number of scores can be earned in a game. Additionally, the scores earned by the same team in different games are assumed to be the outcomes of independent events. As a result, the sum of the scores a team has earned in a season can be represented by a MCP. Similarly, the sum of the scores a team allows in a season can be represented by its own MCP. Each game of a season can be compared to rolling two die; one of the results is added to the home team‚Äôs scores-for (SF) total and the away team‚Äôs scores-against (SA) total, and the other is added to the home team‚Äôs SA total and the away team‚Äôs SF total. A team‚Äôs season scoring total outcome can, therefore, be represented by a point moving through the two-dimensional space of all possible season SF totals and SA totals. . Team ùëñ, for example, can be said to be in state( S_{i}^{n}) at ùëõ games into its season, where (S_{i}^{n} = lbrack S_{i,0}^{n}, S_{i,1}^{n} rbrack = lbrack text{SF}{i}^{n}, text{SA}{i}^{n} rbrack) is the point with components equal to team ùëñ‚Äôs SF and SA totals ùëõ games into its season. In a league with ùê¥ teams, for all teams ùëñ = 1. . . ùê¥ the initial state is (S_{i}^{0} = left lbrack text{SF}{i}^{0}, text{SA}{i}^{0} right rbrack = left lbrack 0, 0 right rbrack) because all teams start a season with zero SF and SA. Playing the ùëõth game in its season transitions team ùëñ from state (S_{i}^{n} )to state (S_{i}^{n + 1}). For an ùëÅ game season, each team ùëñ ends its season in state (S_{i}^{N}), and the components of that state are that team‚Äôs end of season SF and SA totals. . Consecutive state components are related by (S_{i,p}^{n + 1} = S_{i,p}^{n} + X_{i,p}^{n}) and state components separated by (m) games are related by (S_{i,p}^{n + m} = S_{i,p}^{n} + sum_{l = n}^{n + m}X_{i,p}^{l}), where (X_{i}^{n} = left lbrack X_{i,0}^{n},X_{i,1}^{n} right rbrack) is a vector of random variables representing team i‚Äôs ùëõth pair of MCP increments - the amount of scores it earns and allows in the ùëõth game of its season. . The set of states [(S_{i}^{n}) ‚àÄ ùëõ = 0 ‚Ä¶ ùëÅ] is a realization of a MCP process and defines team ùëñ‚Äôs scoring total ‚Äúpath‚Äù. As an example of what realized MCP paths look like, figure 1 plots the 2016-2017 Toronto Maple Leafs SF and SA with respect to season game number along with the rest of the teams in the 2016-2017 NHL season. . . The probability that component ùëù of team ùëñ‚Äôs state vector transitions from (S_{i,p}^{n})= ùë¢ùëù to (S_{i,p}^{n + 1} = v_{p}) is . [P left( S_{i,p}^{n + 1} = v_{p} middle| S_{i,p}^{n} = u_{p} right) = P_{i,uv,p}^{n} = left{ begin{matrix} P left( X_{i,p}^{n} = v_{p} - u_{p} text{ } right), text{ u}{p} leq v{p} text{ } 0, &amp; text{ u}{p} &gt; v{p} end{matrix} right. text{ } left( u,v right) in mathbb{Z}_{+}^{2} (1)] . where (P left( X_{i,p}^{n} = v_{p} - u_{p} text{ } right)) is the probability that the random variable (X_{i,p}^{n}) is equal to ùë£ùëù ‚àí ùë¢ùëù. The probability that component ùëù of team ùëñ‚Äôs state vector transitions from (S_{i,p}^{n})= ùë¢ùëù to (S_{i,p}^{n + m} = v_{p}) is similarly . [P_{i,uv,p}^{n + m} = left{ begin{matrix} P left( sum_{l = n}^{n + m}X_{i,p}^{l} = v_{p} - u_{p} text{ } right), u_{p} leq v_{p} text{ } 0, &amp; text{ u}{p} &gt; v{p} end{matrix} text{ } left( u,v right) in mathbb{Z}_{+}^{2} (2) right. ] . (P_{i,uv,p}^{n + m}) can be interpreted as the entry in the ( text{uth}) row and ( text{vth}) column of a transition probability matrix. Over a season the total number of scores earned and allowed by a team can only increase, and hypothetically any positive integer number of scores can be earned, so the matrix with entries (P_{i,uv,p}^{n + m} ) is an infinite dimensional upper triangular matrix with each entry representing a point in ( mathbb{Z}_{+}^{2}). . The amount of goals a team scores and allows in a game are assumed to be independent random variables, as has been shown to be reasonable [1][2]. The transition probability matrix representing the probability team ùëñ moves from state (S_{i}^{n}) = ùë¢ =[ùë¢0, ùë¢1] to state (S_{i}^{n + m})= ùë£ = [ùë£0, ùë£1] is then the outer product of the component transition probability matrices . [P_{i,u_{0}v_{0}u_{1}v_{1}}^{n + m} = P_{i,uv,0}^{n + m} otimes P_{i,uv,1}^{n + m} (3)] . Each entry of (P_{i,u_{0}v_{0}u_{1}v_{1}}^{n + m} )can also be interpreted as the sum of all likelihood functions that transition team (i) from state ( left lbrack u_{0},v_{0} right rbrack) to state ( left lbrack u_{1},v_{1} right rbrack) in (m) steps. . Team Strength and Strength Transitions . The rates-of-change of a team‚Äôs scores-for total and of its scores-against total are that team‚Äôs scores-for-per-game (SFg) and scores-against-per-game (SAg). The difference between a team‚Äôs SFg and SAg can be considered its ‚Äústrength‚Äù, in the sense that the more scores a team earns per-game and the fewer scores a team allows per-game the stronger the team. For the NHL, the amount of points a team earns in a season ‚Äì which determines the rank of a team compared to the rest of its league - has been shown to strongly correlate with the difference in that team‚Äôs SFg and SAg [3]. If an (N) game NHL season is simulated, as (N) tends to infinity the correlation tends to one. Something something different point-earning scheme as different sorting mechanisms blah blah. Something something find the point-earning scheme that most reliably sorts by the end of a finite length season blah blah. . A team‚Äôs scoring rate, being a ratio of a positive-integer-number of scores and a positive integer number of games, has a domain of( mathbb{Q}{+}^{2}). If team ùëñ is in total scoring state (S{i}^{n}), then that team‚Äôs scoring rate state is . [ text{Sg}{i}^{n} = frac{S{i}^{n}}{n} = left lbrack text{SFg}{i}^{n}, text{SAg}{i}^{n} right rbrack (4)] . Consecutive scoring rate state components are related by the same random variable as consecutive total scoring state components . [ text{Sg}{i,p}^{n + 1} = frac{1}{n + 1} left lbrack n text{Sg}{i,p}^{n} + X_{i,p}^{n} right rbrack (5)] . And, similarly, scoring rate state components separated by (m) games are related by . [ text{Sg}{i,p}^{n + m} = frac{1}{n + m} left lbrack n text{Sg}{i,p}^{n} + sum_{l = n}^{n + m}X_{i,p}^{l} right rbrack (6*)] . Where the star in the equation number implies a derivation is provided in the appendix. Since each ( text{Sg}{i}^{n + m} )depends explicitly on (n), the set of values [( text{Sg}{i}^{n}) ‚àÄ ùëõ = 0 ‚Ä¶ ùëÅ] is a time-inhomogeneous Markov chain. As an example of what scoring rate Markov chains look like, figure 2 displays the 2016-2017 Toronto Maple Leafs SFg and SAg (denoted as GFg and GAg because scores are called ‚Äúgoals‚Äù in the NHL) with respect to season game number along with the rest of the teams in the 2016-2017 NHL season . . The probability that component ùëù of team (i)‚Äôs scoring rate state transitions from ( text{Sg}{i,p}^{n} = u{p}) to ( text{Sg}{i,p}^{n + 1} = v{p}) is ( text{Pg}{i,uv,p}^{n}). Solving for the sum of random variables in the definition of ( text{Sg}{i,p}^{n + 1}) lets it be stated that . [{P left( text{Sg}{i,p}^{n + 1} = v{p} middle| text{Sg}{i,p}^{n} = u{p} right) = Pg}{i,uv,p}^{n} = left{ begin{matrix} P(X{i,p}^{n} = left( n + 1 right)v_{p} - nu_{p} ;u_{p} = frac{a}{n}, v_{p} = frac{b + a}{n + 1} (a,b) in mathbb{Z}_{+}^{2} 0 text{otherwise} end{matrix} right. (7)] . Where (u_{p} = frac{b}{n}, v_{p} = frac{a + b}{n + 1} (a,b) in mathbb{Z}{+}^{2}) are the constraints resulting from requiring the number of goals to be a positive integer. Similarly, the probability that component (p) of team ùëñ‚Äôs scoring rate transitions from ( text{Sg}{i,p}^{n} = u_{p}) to ( text{Sg}{i,p}^{n + m} = v{p}) is . ( text{Pg}{i,uv,p}^{n + m} = left{ begin{matrix} P( sum{n = l}^{n + m}X_{i,p}^{l} = left( n + m right)v_{p} - nu_{p} ;u_{p} = frac{a}{n}, v_{p} = frac{b + a}{n + m} (a,b) in mathbb{Z}_{+}^{2} 0 text{otherwise} end{matrix} right. (8*)). . ( text{Pg}{i,uv,p}^{n + m}) can be interpreted as the entry in the ( text{uth}) row and ( text{vth}) column of a transition probability matrix. The transition probability matrix for team ùëñ to move from strength ( text{Sg}{i}^{n}) = ùë¢ =[ùë¢0, ùë¢1] to strength ( text{Sg}_{i}^{n + m})= ùë£ = [ùë£0, ùë£1] is then the outer product of the component strength transition probability matrices . [ text{Pg}{i,u{0}v_{0}u_{1}v_{1}}^{n + m} = text{Pg}{i,uv,0}^{n + m} otimes text{Pg}{i,uv,1}^{n + m} (9)] . The non-zero entries of the matrices [( text{Pg}{i,u{0}v_{0}u_{1}v_{1}}^{n} forall i = 1 ldots A,n = 0 ldots N rbrack) define the complete set of allowable scoring rate outcomes for a season. A non-allowable strength result, for example, would be a team having ( text{Sg}_{i}^{10} = 2.55), because that would imply the team had 25.5 scores. . Application of the Markov Chain Model to the NHL | The formalism developed in sections two and three is not sport specific ‚Äì the transition probabilities can be applied to any sport in which the number of scores earned in a game can be approximated as a draw from some positive-integer-domain probability distribution. To apply the formalism to a specific sport, the probability distribution representing the likelihood that a certain amount of scores are earned in a game for that sport must be inserted into the transition probabilities. . Scoring in hockey has been shown to be approximately Poisson [1][2][4]. That is, the number of goals a team scores and allows in a game can be approximated as independent random draws from Poisson distributions. . [X_{i,p}^{n} sim P( mu_{i,p}^{n}) (10)] . Where ( mu_{i,0}^{n}) and ( mu_{i,1}^{n}) represent the number of goals team (i) is expected to score and allow, respectively, in game (n). Hockey is not a purely Poisson process, though, as expected scoring is not uniform over every slice of time in a game. Goals are scored at a disproportionately high rate at the ends of periods - especially at the end of the third period ‚Äì and during odd man situations [1][2][5]. . Ignoring the NHL‚Äôs deviation from a purely Poisson process and dropping the component notation for clarity, the probability team (i)‚Äôs total scoring state transitions from state (u) to state (v) in game (n) can be written as . [P left( X_{i}^{n} = v - u right) = frac{e^{- ( mu_{i}^{n})}({ mu_{i}^{n})}^{v - u}}{(v - u)!} text{ } left( 11 right)] . The sum of Poisson variables is a Poisson variable with a mean of the sum of the constituent variable means. Consequently, the probability team (i)‚Äôs total scoring state transitions from state (u) in game (n) to state (v) in game (n + m) can be written as . [P left( sum_{l = n}^{n + m}X_{i}^{l} = v - u right) = frac{e^{- ( sum_{l = n}^{n + m} mu_{i}^{l})}({ sum_{l = n}^{n + m} mu_{i}^{l})}^{(v - u)}}{(v - u)!} (12)] . And the scoring transition probability matrix can be written as . [P_{i,uv}^{n + m} = left{ begin{matrix} frac{e^{- ( sum_{l = n}^{n + m} mu_{i}^{l})}({ sum_{l = n}^{n + m} mu_{i}^{l})}^{(v - u)}}{(v - u)!}, u leq v 0, &amp; u &gt; v end{matrix} right. text{ } left( u,v right) in mathbb{Z}_{+}^{2} (13)] . Scoring rate transition probabilities depend on the same Poisson random variable as total scoring transition probabilities. As such, the probability team (i)‚Äôs scoring rate transitions from state (u) in game (n) to state (v) in game (n + m) is . [P left( sum_{l = n}^{n + m}X_{i}^{l} = left( n + m right)v - nu right) = frac{e^{- ( sum_{l = n}^{n + m} mu_{i}^{l})}({ sum_{l = n}^{n + m} mu_{i}^{l})}^{ lbrack left( n + m right)v - nu rbrack}}{ lbrack left( n + m right)v - nu rbrack!} (14)] . And the strength transition probability matrix entries can be written as . [ text{Pg}{i,uv}^{n + m} = left{ begin{matrix} frac{e^{- ( sum{l = n}^{n + m} mu_{i}^{l})}({ sum_{l = n}^{n + m} mu_{i}^{l})}^{ lbrack left( n + m right)v - nu rbrack}}{ lbrack left( n + m right)v - nu rbrack!};u = frac{a}{n}, v = frac{b + a}{n + m} (a,b) in mathbb{Z}_{+}^{2} 0 text{otherwise} end{matrix} right. (15*)] . Comparing Predicted Transition Probabilities to NHL Data | In order to determine if the transition probability ( text{Pg}{i,uv}^{n + m} )actually represents the probability an NHL team goes from scoring rate (u) at game (n) to scoring rate (v) at game (n + m), transition probabilities estimated using equation 15 must be compared to values calculated using actual NHL data. Ideally, the Markov chain probabilities calculated using equation 15 could be directly contrasted to Monte-Carlo probabilities calculated using an NHL data sample population. For example, the set of A NHL teams that reached state ( text{Sg}{i}^{n} = u) and the subset of B teams that subsequently reached state ( text{Sg}{i}^{n + m} = v) would be counted. The probability an NHL team reaches state ( text{Sg}{i}^{n + m} = v) given it was in state ( text{Sg}{i}^{n} = u) could then be estimated by ( frac{B}{A}) and compared to ( text{Pg}{i,uv}^{n + m}). . Unfortunately, for most transitions, there haven‚Äôt been enough teams( )that reached the exact same final state from the exact same initial state in order to directly make meaningful estimates of transition probabilities. Instead, in order to make transition probability estimations with NHL data, a range of potential (u) and (v) values were tolerated. . Allowing for a tolerance ( delta) in (u) and (v) results in the following method for estimating transition probabilities with NHL data: the set of A NHL teams with ( text{Sg}{i}^{n}) in the range ( lbrack u - delta,u + delta rbrack) and the subset of B teams with ( text{Sg}{i}^{n + m}) in the range ( lbrack v - delta,v + delta rbrack) are counted. The probability a team reaches a state ( text{Sg}{i}^{n + m}) in the range ( lbrack v - delta,v + delta rbrack) given it had a state ( text{Sg}{i}^{n} )in the range ( left lbrack u - delta,u + delta right rbrack )is then estimated by . [P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta right | left | text{Sg}_{i}^{n} - u right | &lt; delta) approx frac{B}{A} equiv NHL left( u,v,n,m, delta right) (16)] | . For example, in the last 10 NHL seasons there have been 52 teams that had between 2.9 and 3.1 GFg 41 games into their season. Of those teams, 19 had between 2.9 and 3.1 GFg 82 games into their season. NHL data therefore estimates that the probability a team reaches a state ( text{Sg}{i}^{82}) in the range ( lbrack 3 - .1, 3 + .1 rbrack) given it had state ( text{Sg}{i}^{41}) in the range ( lbrack 3 - .1, 3 + .1 rbrack )to be ( text{NHL} left( 3,3,41,82,.1 right) = frac{19}{52} = .365. )Probabilities produced with this method can be contrasted to a modified version of (15): . [P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta right | left | text{Sg}_{i}^{n} - u right | &lt; delta) approx frac{ sum_{z}^{} frac{e^{- n mu} left( text{nŒº} right)^{ text{nz}}}{ left( text{nz} right)!} sum_{x = left( n + m right)v - nz - delta left( n + m right)}^{ left( n + m right)v - nz + delta left( n + m right)} frac{e^{- m mu} left( text{mŒº} right)^{x}}{x!}}{ sum_{z}^{} frac{e^{- n mu} left( text{nŒº} right)^{ text{nz}}}{ left( text{nz} right)!}} equiv MC left( u,v,n,m, delta right) (17*)] | . Where the domain of (z) is all allowable values of ( text{Sg}_{i}^{n}) in the range ( lbrack u - delta,u + delta rbrack); ( mu) is an approximation of the expected amount of goals in a game for the average NHL team, taken to equal the last 10 NHL seasons‚Äô average GFg; and MC stands for Markov Chain. Applying (17) to the preceding sample parameter set results in ( text{MC} left( 3,3,41,82,.1 right) = .357.) . 100 parameter sets ( theta_{x} = left( u,v,n,m, delta right){x}) were pseudo-randomly generated, and the values of ( text{MC} left( theta{x} right)) and (NHL( theta_{x})) were calculated for each. A linear regression was then run between the two sets of resulting probabilities. The fit takes the form . [ text{MC} left( theta_{x} right) = alpha NHL left( theta_{x} right) + beta + varepsilon_{x} (18)] . where ( alpha) and ( beta) are constants and ( varepsilon) is a Normally distributed error term. If (MC( theta)) were equal to (NHL( theta)) for every parameter set, then the fit parameters would be ( left lbrack alpha, beta right rbrack = lbrack 1,0 rbrack), the r-squared value would be (r = 1,) and each error term would be zero. Only a finite number of NHL games have been played, ( mu) is only an approximation, and hockey is not a purely Poisson process, though, so both (NHL( theta)) and (MC( theta)) are expected to only be approximations of the true probability corresponding to the parameter set ( text{Œ∏.}) As a result, some deviation of the data from the ideal fit parameters, an r-squared value less than 1, and non-zero error variance should be expected. . Average values of the fit parameters were found to be ( left lbrack alpha, beta right rbrack = lbrack 0.994, .032 rbrack), the average r-squared value was found to be (.887), and the errors were approximately Normally distributed with a mean of zero and a variance of .0082. The parameter results are only point estimates, but the true parameters are in the ranges (0.923 leq alpha leq 1.065) and (- .6002 leq beta leq 0.066) with 95% confidence. These results suggest that (MC( theta)) is equal to (NHL( theta)) plus noise resulting from the imperfect approximations made in calculating the two predictions: . [ text{MC} left( theta right) approx NHL left( theta right) + N(0, 0.0082) (19)] . . Residual analysis of the linear fit suggests that, while the relation between (MC( theta)) and (NHL( theta)) is not perfectly linear, the linear fit is a reasonable approximation. The success of the Markov chain equations in modeling NHL data suggests that modeling the NHL as a set of Markov chains with Poisson transition probabilities is justified. . Derivations of Starred Equations . (6): ( text{Sg}{i}^{n + m} = frac{S{i}^{n + m}}{n + m} = frac{n}{n} left( frac{S_{i}^{n} + sum_{l = n}^{n + m}X_{i}^{l}}{n + m} right)) (= frac{1}{n + m}( frac{nS_{i}^{n}}{n} + sum_{l = n}^{n + m}X_{i}^{l}) = frac{1}{n + m}(n text{Sg}{i}^{n} + sum{l = n}^{n + m}X_{i}^{l})) . (8): ( text{Sg}{i}^{n + m} = frac{1}{n + m} left( n text{Sg}{i}^{n} + sum_{l = n}^{n + m}X_{i}^{l} right) rightarrow left( n + m right) text{Sg}{i}^{n + m} - n text{Sg}{i}^{n} = sum_{l = n}^{n + m}X_{i}^{l} rightarrow) . [P left( text{Sg}_{i}^{n + m} = v middle | text{Sg}{i}^{n} = u right) = P( sum{l = n}^{n + m}X_{i}^{l} = left( n + m right)v - nu)] | . The sum of goals must be a positive integer, therefore allowable values of (u) and (v) for given (n,m) are . (u = frac{b}{n}, v = frac{a + b}{n + m}, (a,b) in mathbb{Z}{+}^{2} rightarrow) ( text{Pg}{i,uv}^{n + m} = left{ begin{matrix} P( sum_{l = n}^{n + m}X_{i}^{l} = left( n + m right)v - nu) ;u = frac{b}{n},v = frac{a + b}{n + m}, (a,b) in mathbb{Z}_{+}^{2} 0 text{otherwise} end{matrix} right. ) . (15): ( lim_{n rightarrow infty}{ text{Sg}{i}^{n + 1} = { lim{n rightarrow infty} }{ frac{1}{n + 1} left lbrack n text{Sg}{i}^{n} + X{i}^{n} right rbrack}} = lim_{n rightarrow infty} frac{n text{Sg}{i}^{n}}{n + 1} + lim{n rightarrow infty} frac{X_{i}^{n}}{n + 1}) (= lim_{n rightarrow infty} frac{ text{Sg}{i}^{n}}{1} + 0 = text{Sg}{i}^{n}) . (17): By the definition of conditional probability (P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta right | left | text{Sg}_{i}^{n} - u right | &lt; delta) = frac{P( left | text{Sg}_{i}^{n + m} - v right | &lt; delta cap left | text{Sg}_{i}^{n} - u right | &lt; delta)}{P( left | text{Sg}_{i}^{n} - u right | &lt; delta)}) | . This derivation finds expressions for both the denominator and the numerator of the above quotient individually, then combines them to form an expression for (P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta right | left | text{Sg}_{i}^{n} - u right | &lt; delta)). | . Denominator: The probability a team will have ( text{Sg}_{i}^{n} = z) is the probability that the sum of the goals scored in the first n games equals ( text{nz}): . [P left( text{Sg}{i}^{n} = z right) = P left( sum{l = 0}^{n}X_{i}^{l} = nz right) = frac{e^{- n mu}{(n mu)}^{ text{nz}}}{ left( text{nz} right)!}] . For some expected amount of goals in a game ( mu). The probability a team will have ( left | text{Sg}_{i}^{n} - u right | leq delta) is then the sum of (P left( text{Sg}_{i}^{n} = z right)) over all values of (z) such that ( left | z - u right | leq delta) | . [P left( left | text{Sg}_{i}^{n} - u right | leq delta right) = sum_{z}^{} frac{e^{- n mu}{(n mu)}^{ text{nz}}}{ left( text{nz} right)!}] | . Numerator: For a team to go from ( text{Sg}_{i}^{n} = z) to ( left | text{Sg}_{i}^{n + m} - v right | leq delta), there are a minimum amount of goals and a maximum amount of goals that can be scored. The minimum amount of goals would take the team to ( text{Sg}{i}^{n + m} = v - delta), and the maximum amount of goals would take them to ( text{Sg}{i}^{n + m} = v + delta). The probability a team has ( left | text{Sg}_{i}^{n + m} - v right | leq delta) given it had ( text{Sg}_{i}^{n} = z) is then | . (P left( left | text{Sg}_{i}^{n + m} - v right | leq delta right | text{Sg}{i}^{n} = z)) (= P lbrack left( n + m right) left( v - delta right) - nz leq sum{l = n}^{n + m}X_{i}^{l} leq left( n + m right) left( v + delta right) - nz rbrack) | . [= P lbrack left( n + m right)v - nz - delta left( n + m right) leq sum_{l = n}^{n + m}X_{i}^{l} leq left( n + m right)v - nz + delta left( n + m right) rbrack = sum_{x = left( n + m right)v - nz - delta(n + m)}^{(n + m)v - nz + delta(n + m)} frac{e^{- m mu}{(m mu)}^{x}}{x!}] . Since goals in different games, and therefore different clusters of games, are assumed to be independent variables, the probability a team will go from ( text{Sg}{i}^{0} = 0) to ( text{Sg}{i}^{n} = z) and from ( text{Sg}_{i}^{n} = z) to ( left | text{Sg}_{i}^{n + m} - v right | leq delta) is(P left( left | text{Sg}_{i}^{n + m} - v right | leq delta cap text{Sg}{i}^{n} = z right) = P left( text{Sg}{i}^{n} = z right)*P left( left | text{Sg}_{i}^{n + m} - v right | leq delta right | text{Sg}_{i}^{n} = z)). The probability a team will have ( left | text{Sg}_{i}^{n} - u right | leq delta) and ( left | text{Sg}_{i}^{n + m} - v right | leq delta) is the sum of (P left( left | text{Sg}_{i}^{n + m} - v right | leq delta cap text{Sg}_{i}^{n} = z right) )over all values of (z) such that ( left | z - u right | leq delta). Then, (P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta cap left | text{Sg}_{i}^{n} - u right | &lt; delta right) = sum_{z}^{}{P( text{Sg}_{i}^{n} = z cap left | text{Sg}_{i}^{n + m} - v right | leq delta)}) | . [= sum_{z}^{}{P left( text{Sg}_{i}^{n} = z right)*P left( left | text{Sg}_{i}^{n + m} - v right | leq delta right | text{Sg}{i}^{n} = z)} = sum{z}^{}{ frac{e^{- n mu}{(n mu)}^{ text{nz}}}{ left( text{nz} right)!}* sum_{x = left( n + m right)v - nz - delta(n + m)}^{(n + m)v - nz + delta(n + m)} frac{e^{- m mu}{(m mu)}^{x}}{x!}}] | . Then, by combining the derived numerator and denominator with the definition of conditional probability, . [P left( left | text{Sg}_{i}^{n + m} - v right | &lt; delta right | left | text{Sg}_{i}^{n} - u right | &lt; delta) = frac{ sum_{z}^{} frac{e^{- n mu}{(n mu)}^{ text{nz}}}{ left( text{nz} right)!} sum_{x = left( n + m right)v - nz - delta(n + m)}^{(n + m)v - nz + delta(n + m)} frac{e^{- m mu}{(m mu)}^{x}}{x!}}{ sum_{z}^{} frac{e^{- n mu}{(n mu)}^{ text{nz}}}{ left( text{nz} right)!}}] | . Citations . [1] Dayaratna, K. and Miller, S. (2012). Pythagorean Win-Loss formula and Hockey . [2] Ryder, A. (2004). Poisson Toolbox: a review of the application of the Poisson Probability Distribution in hockey . [3] Found, R. (2016). Goal-based Metrics Better Than Shot-based Metrics at Predicting Hockey Success . [4] Morrison, D.G. (1976). On the optimal time to pull the goalie: A Poisson model applied to a common strategy used in ice hockey. TIMS Studies in Management Science, Vol. 4. . [5] Thomas, A. (2007). Inter-Arrival Times Of Goals In Hockey . [ ] .",
            "url": "https://dankee-yoodle.github.io/iob/2020/05/23/Actual-NHL-Markov-Chain-Paper.html",
            "relUrl": "/2020/05/23/Actual-NHL-Markov-Chain-Paper.html",
            "date": " ‚Ä¢ May 23, 2020"
        }
        
    
  
    
  
    
  
    
  
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it‚Äôs in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://dankee-yoodle.github.io/iob/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://dankee-yoodle.github.io/iob/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}