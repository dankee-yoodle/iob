{
  
    
  
    
  
    
  
    
        "post3": {
            "title": "Title",
            "content": "Introduction . In this note I introduce a Naive Bayes framework for estimating the competence of an institution in representing the interest of the public, for the simple case of an institution which makes binary decisions exclusively informed by independently voting representatives of the public. Making the assumptions 1) that the competence of a representative in representing the public interest can be approximated by a function of the public approval and disapproval ratings of the representative and 2) that public approval and disapproval ratings of a representative can be approximated by the public approval and disapproval ratings of the political party of the representative, I then use Gallup&#39;s Party Images polling and CSPAN voting records to estimate the competence of the chambers of the United States Congress in representing the public interest over successive six-month periods from 1993 to the present. . Naive Bayes Framework for Estimating the Competence of an Institution . An institution can be defined as acting in the public interest when making a decision if it makes the decision most likely to be in the public interest given the available evidence. Under that definition, the competence of an institution in representing the public interest over some time period can be approximated by the agreement between the decisions actually made by the institution during that time period and the decisions which were most likely to be in the public interest given the available evidence. Calling the decision most likely to be in the public interest given the available evidence the &quot;epistemic decision&quot; as shorthand, under this approximation an institution which always made the epistemic decision would have a competence of $1$ for the time period and an institution which never made the epistemic decision would have a competence of $0$ for the time period. . If the evidence available to inform each institutional decision is an observed voting profile of a body of representatives of the public, then the competence of an institution over a time period is the agreement between the decisions actually made by the institution during that time period and the decisions most likely to be in the public interest given the observed representative voting profiles. Therefore, if I can define a method for determining the epistemic decision given an observed voting profile of a body of representatives of the public as evidence, then, by comparing the actual institutional decisions to the epistemic decisions determined by the method, I can estimate the competence of an institution in representing the public interest over a time period. . In order to define a method for determining the epistemic decision given an observed voting profile of a body of representatives of the public as evidence, and therefore be able to estimate the competence of institutions which make binary decisions informed by voting profiles of bodies of representatives of the public, this section first reviews how Bayes theorem can be applied in a binary setting to estimate the probability a decision is correct given a set of evidence, then reviews how an observed voting profile can be used as evidence. . Bayes Theorem for Binary Decisions . Assume a decision must be made between two options - call them option $1$ and option $-1$. Assume one of the options is &quot;correct&quot; - call it option $X$. Assume the decision is to be informed exclusively by a set of evidence $v$, which implies both options are equally probable prior to considering $v$. The respective posterior probabilities of option $-1$ and option $1$ being correct having considered evidence $v$ are then the respective probabilities of observing the evidence $v$ given option $-$ and option $1$ being correct relative to the total probability of observing the evidence $v$. . $$P(X=1|v) = frac{P(v|X=1)}{P(v|X=1) + P(v|X=-1)}$$ . $$P(X=-1|v) = frac{P(v|X=-1)}{P(v|X=1) + P(v|X=-1)}$$ . Where $P(v|X=1)$ is the probability of observing the evidence $v$ given the correct option being $1$ and $P(v|X=-1)$ is similarly the probability of observing the evidence $v$ given the correct option being $-1$. In general, the probability option $x$ is the correct option given observed evidence $v$ is . $$P(X=x|v) = frac{P(v|X=x)}{ sum_{x} P(v|X=x)}$$ . Where the sum is over all possibilities for the correct option. The value of $x$ for which $P(X=x|v)$ is maximized is the option most likely to be correct given the available evidence $v$. . Voting as Producing Evidence . Assume a body of N voters is to produce the evidence meant to inform a decision between two options - call them option $1$ and option $-1$. Assume one of the options is correct - call it option $X$. By Bayes theorem, The probability that the $x$th option is correct given an observed voting profile $ vec{v}=[v_1,v_2,...v_N]$ as evidence is . $$P(X=x| vec{v}) = frac{P( vec{v}|X=x)}{ sum_{x} P( vec{v}|X=x)}$$ . If the voters vote independently conditional on the correct decision such that . $$P(v_i=u|v_j=w,X=x) = P(v_i=u|X=x)P(v_j=w|X=x) , forall , (i,j,x,u,v) , i neq j$$ . and the $i$th voter is assumed have competence $p_i$ such that . $$P(X=1|v_i=1)=P(X=-1|v_i=-1)=p_i$$ $$P(X=-1|v_i=1)=P(X=-1|v_i=1)=1-p_i$$ . then the probability of observing the voting profile $ vec{v}$ given the correct choice being the $x$th option is . $$P( vec{v}|X=x)= prod_{i=1}^{N}p^{ frac{1+v_ix}{2}}(1-p)^{ frac{1-v_ix}{2}}$$ . And the probability that the $x$th option is correct given the voting profile $ vec{v}$ as evidence simplifies to . $$P(X=x| vec{v}) = frac{1}{1+ prod_{i=1}^{N}( frac{p_i}{1-p_i})^{-xv_i}}$$ . For a given a set of voter competence parameters $ vec{p}$, the value of x which maximizes this equation is the option most likely to be correct given an observed voting profile $ vec{v}$ as evidence. . Application to the United States Congress . The chambers of the United States Congress make institutional decisions by majority rule. Generally, the decisions are between taking and not taking an institutional action. For each action considered by a chamber, each representative of the chamber votes Yea or Nay; if a majority (or supermajority) of the representatives vote Yea, then the proposed action is taken; if not, then the proposed action is not taken. . Congressional voting profiles and the resulting institutional decisions are available on CSPAN&#39;s website [votes_house] [votes_senate] for each roll-call vote since 1989. If I assume vectors of representative competencies for each vote, then, by applying the method defined in the previous section, I can use the congressional voting profiles to estimate the corresponding epistemic decisions, and I can compare those epistemic decisions to the institutional decisions actually made over some time period in order to estimate the competencies of the chambers of Congress in representing the public interest during that time period. . It is, of course, not possible to know the actual values of the parameters; there is no way of knowing exactly how competent a representative is in representing the public interest. In lieu of having the resources necessary to determine reasonable estimates empirically, the best I can do is make heuristically reasonable assumptions as to what the parameters might be approximated by, then interpret the resulting estimations as approximations particular to the assumptions. . This section first goes over the competence parameter assumptions I have made and how they might be improved upon, then uses the assumed parameters to estimate the competencies of the chambers of the U.S. Congress over successive six-month periods from 1993 to the present. . Representative Competence Assumption . I assume the competence of a representative in representing the public interest can be approximated by a function of the approval and disapproval ratings of the representative. For simplicity, I take the function which maps ratings to competence to be the logistic of the difference between public approval and disapproval. This mapping assures that a representative who is more approved than disapproved by the public will be more likely than not to vote in the public interest and that representative competence increases diminishingly as the difference between representative approval and disapproval increases. . Unfortunately, approval polling of individual representatives is sparse; generally it only occurs when they are running for office. Consequently, I&#39;m forced to assume that the public approval and disapproval ratings of a representative can be approximated by those of the political party of the representative. This assumption allows me to use the long-running Gallup Party Images poll [party_images] to estimate the competencies of Democratic and Republican representatives at the time of each congressional vote from 1993 - the first year the poll ran - to the present. Because the public frequently elects representatives based on their party affiliation instead of their individual characteristics, and because representatives frequently vote along party lines instead of according to individual convictions, I feel that this assumption is heuristically reasonable. . Applying these two assumptions, I take the competencies of Democratic and Republican representatives for past votes to be . $$p_D= frac{1}{1+e^{-(approval_{D,t}-disapproval{D,t})}}$$ $$p_R= frac{1}{1+e^{-(approval_{R,t}-disapproval{R,t})}}$$ . Where $approval_{D,t}$ is the decimal-percent approval rating of the Democratic party as reported on date $t$, the closest date to the vote a poll result was reported; $disapproval_{D,t}$ is the decimal-percent disapproval rating of the Democratic party as reported on the same date; and $approval_{R,t}$ and $disapproval{R,t}$ are similarly the decimal-percent approval and disapproval ratings for the Republican party. For example, polls concluding on September 15th 2019 reported the Democratic party as having decimal-percent approval and disapproval ratings of .48 and .50, respectively, and the Republican party as having decimal-percent approval and disapproval ratings of .43 and .55. Consequently, for dates of votes closer to September 15th 2019 than to any other date polls concluded, I take the competencies of Democratic and Republican representatives, $p_D$ and $p_R$, to be . $$p_D= frac{1}{1+e^{-(.48-.50)}} = .495$$ $$p_R= frac{1}{1+e^{-(.43-.55)}} = .470$$ . The figure below displays the competencies of Democratic and Republican representatives from 1993 to the present, calculated using the above method. These are the values which I take as representative competencies while producing the institution-epistemic agreement plots displayed in the next section. . #collapse-hide import pandas as pd import numpy as np import matplotlib.pyplot as plt import time import math import datetime import requests from bs4 import BeautifulSoup as soup def logistic(attack,defense): x = 1/(1+math.exp(-1*(attack-defense))) return x party_approval_dict = {} # {time: {party:value}} approval_url = &#39;https://news.gallup.com/poll/24655/party-images.aspx&#39; r = requests.get(approval_url) approval_page = soup(r.text,&#39;lxml&#39;) democratic_approval_table = approval_page.find_all(&#39;table&#39;)[0] republican_approval_table = approval_page.find_all(&#39;table&#39;)[1] td = pd.read_html(str(democratic_approval_table))[0] favorable_d = list(td.loc[:,&#39;Favorable&#39;][0:-1].loc[:,&#39;%&#39;]) unfavorable_d = list(td.loc[:,&#39;Unfavorable&#39;][0:-1].loc[:,&#39;%&#39;]) tr = pd.read_html(str(republican_approval_table))[0] favorable_r = list(tr.loc[:,&#39;Favorable&#39;][0:-1].loc[:,&#39;%&#39;]) unfavorable_r = list(tr.loc[:,&#39;Unfavorable&#39;][0:-1].loc[:,&#39;%&#39;]) dates = list(td.iloc[:,[0]][0:-1].iloc[:,0]) dates = [&#39; &#39;.join(x.split()[0:2] + [x.split()[2]]).split(&#39;-&#39;)[0] for x in dates] for i in range(len(dates)): try: ad = float(favorable_d[i])/100 except: continue dd = float(unfavorable_d[i])/100 vald = logistic(ad,dd) ar = float(favorable_r[i])/100 dr = float(unfavorable_r[i])/100 valr = logistic(ar,dr) party_approval_dict[dates[i]] = {&#39;D&#39;:round(vald,3),&#39;R&#39;:round(valr,3)} def PartyRating(date): #takes date of format &#39;December 2012, 21&#39; and finds party ratings closest to that date d_get_compare = time.mktime(time.strptime(date,&#39;%B %d, %Y&#39;)) d_list = [time.mktime(time.strptime(x,&#39;%Y %b %d&#39;)) for x in party_approval_dict.keys()] d_deltas = [abs(d_get_compare - x) for x in d_list] index_min = np.argmin(d_deltas) d_closest = d_list[index_min] d = time.strftime(&#39;%Y %b %d&#39;,time.localtime(d_closest)) if d.split()[-1][0] == &#39;0&#39;: d = &#39; &#39;.join(d.split()[0:-1]) + &#39; &#39; + d.split()[-1][1:] return party_approval_dict[d] . . #collapse-hide from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() rate_data = sorted([[time.mktime(time.strptime(x,&#39;%Y %b %d&#39;)),party_approval_dict[x]] for x in party_approval_dict.keys()], key=lambda x: x[0]) ds = [datetime.datetime.fromtimestamp(x[0]) for x in rate_data] dem_rates = [x[1][&#39;D&#39;] for x in rate_data] rep_rates = [x[1][&#39;R&#39;] for x in rate_data] plt.figure(figsize=(10,3)) plt.grid() plt.plot(ds, dem_rates,&#39;b&#39;) plt.plot(ds, rep_rates,&#39;r&#39;) plt.xlabel(&#39;Date&#39;,fontsize=13) plt.ylabel(&#39;Competence&#39;,fontsize=13) plt.title(&#39;Party Competence 1993-Present&#39;,fontsize=16) plt.legend([&#39;Democratic&#39;,&#39;Republicans&#39;], loc=(.42,-.45)) plt.show() . . This competence parameter assumption could be improved by fitting a trend line to the poll results then taking the competencies from the exact date on the fit line instead of from the date of the nearest reported poll result. The assumptions could be further improved by conducting and aggregating a number of national polls asking how much each individual representative is trusted to act in the public interest. Preferably the polls would be taken at regular intervals and according to a regular standard. This would allow representatives to be treated as individuals instead of as homogeneous party members, and for the opinions of the public to directly factor into a standardized measure of the competence of institutions in representing the public. . Institutional-Epistemic Decision Agreement . #collapse-hide import dill import os data_dir = &#39;data cspan &#39; senate_votes = [{},{},{}] house_votes = [{},{},{}] congress_votes = [{},{},{}] for congress_number in range(103,116): with open(data_dir + &#39;cspan_c&#39; + str(congress_number) +&#39;_senate.pkl&#39;,&#39;rb&#39;) as f: known_votes = dill.load(f) senate_votes[0].update(known_votes[0]) senate_votes[1].update(known_votes[1]) senate_votes[2].update(known_votes[2]) congress_votes[0].update(known_votes[0]) congress_votes[1].update(known_votes[1]) congress_votes[2].update(known_votes[2]) with open(data_dir + &#39;cspan_c&#39; + str(congress_number) +&#39;_house.pkl&#39;,&#39;rb&#39;) as f: known_votes = dill.load(f) house_votes[0].update(known_votes[0]) house_votes[1].update(known_votes[1]) house_votes[2].update(known_votes[2]) congress_votes[0].update(known_votes[0]) congress_votes[1].update(known_votes[1]) congress_votes[2].update(known_votes[2]) with open(data_dir + &#39;cspanSenate.pkl&#39;,&#39;rb&#39;) as f: known_votes = dill.load(f) senate_votes[0].update(known_votes[0]) senate_votes[1].update(known_votes[1]) senate_votes[2].update(known_votes[2]) with open(data_dir + &#39;cspanHouse.pkl&#39;,&#39;rb&#39;) as f: known_votes = dill.load(f) house_votes[0].update(known_votes[0]) house_votes[1].update(known_votes[1]) house_votes[2].update(known_votes[2]) . . #collapse-hide chambers = [&#39;House&#39;,&#39;Senate&#39;] for chamber in chambers: if chamber == &#39;House&#39;: known_votes = house_votes elif chamber == &#39;Senate&#39;: known_votes = senate_votes bill_result_dict = known_votes[0] senator_vote_dict = known_votes[1] senator_party_dict = known_votes[2] ############################################################ #calculate probabilities ############################################################ def NaiveBayes(pc,competences,votes): Q=1 for i in range(len(votes)): Q = Q*(((-1)**(votes[i]))*(competences[i]-votes[i]))/float(((-1)**(1-votes[i]))*(competences[i]-votes[i])+1) return 1/float(1 + Q*(1-pc)/float(pc)) pass_words = [&#39;confirmed&#39;,&#39;passed&#39;,&#39;agreed to&#39;,&#39;sustained&#39;] yes_vote_words = [&#39;Aye&#39;,&#39;Yes&#39;,&#39;Yea&#39;,&#39;Guilty&#39;] no_vote_words = [&#39;Nay&#39;,&#39;No&#39;,&#39;Not Guilty&#39;] prob_dict = {} for bill in bill_result_dict.keys(): date = &#39; &#39;.join(bill_result_dict[bill][&#39;date&#39;].split()[0:-1]) date_party_approval_dict = PartyRating(date) competences = [] votes = [] for senator in sorted(bill_result_dict[bill][&#39;voters&#39;].keys()): try: if senator_party_dict[senator] == &#39;Democratic&#39;: competence = date_party_approval_dict[&#39;D&#39;] elif senator_party_dict[senator] == &#39;Republican&#39;: competence = date_party_approval_dict[&#39;R&#39;] else: #print(&#39;why no favoribility poll for independents?&#39;,senator) continue vote = bill_result_dict[bill][&#39;voters&#39;][senator] competences.append(competence) votes.append(vote) except: continue vs = [] cs = [] for voter_idx in range(len(votes)): if votes[voter_idx] in yes_vote_words: vs.append(1) cs.append(competences[voter_idx]) elif votes[voter_idx] in no_vote_words: vs.append(0) cs.append(competences[voter_idx]) else: continue prob = NaiveBayes(.5, cs, vs) prob_dict[bill] = prob ############################################################ #calculate congress competency ############################################################ def ForecastQuality(trues, forecast): a = 0 b = 0 c = 0 d = 0 for i in range(len(trues)): if forecast[i] == 1 and trues[i] == 1: a += 1 elif forecast[i] == 1 and trues[i] == 0: b += 1 elif forecast[i] == 0 and trues[i] == 0: d += 1 elif forecast[i] == 0 and trues[i] == 1: c += 1 pcorrect = (a+d)/float(a+b+c+d) quality = [round(pcorrect,3)] return quality def CongressQuality(t_i,t_f): epistemic = [] congressional = [] for bill in prob_dict.keys(): bill_date = &#39; &#39;.join(bill_result_dict[bill][&#39;date&#39;].split()[0:-1]) bill_date_compare = time.mktime(time.strptime(bill_date,&#39;%B %d, %Y&#39;)) if t_i &lt;= bill_date_compare &lt; t_f: if prob_dict[bill] &gt; .5: epistemic.append(1) elif prob_dict[bill] &lt; .5: epistemic.append(0) else: continue if bill_result_dict[bill][&#39;status&#39;] == &#39;PASS&#39;: congressional.append(1) else: congressional.append(0) congress_quality = ForecastQuality(epistemic,congressional) return congress_quality max_date = max([time.mktime(time.strptime(&#39; &#39;.join(bill_result_dict[bill][&#39;date&#39;].split()[0:-1]),&#39;%B %d, %Y&#39;)) for bill in bill_result_dict]) min_date = min([time.mktime(time.strptime(&#39; &#39;.join(bill_result_dict[bill][&#39;date&#39;].split()[0:-1]),&#39;%B %d, %Y&#39;)) for bill in bill_result_dict]) n_points = 52 date_increment = (max_date - min_date)/n_points date_ranges = [min_date + x*date_increment for x in range(n_points)] accuracies = [] quality_dates = [] t_f = &#39;init&#39; for date_idx in range(len(date_ranges)): if t_f != date_ranges[-1]: t_i = date_ranges[date_idx] t_f = date_ranges[date_idx + 1] cq = CongressQuality(t_i,t_f) accuracies.append(cq[0]) quality_dates.append(datetime.datetime.fromtimestamp(t_f)) else: continue ############################################################ # plot results ############################################################ date_prob_pairs_passed = [] date_prob_pairs_failed = [] weird_ones = [] for bill in bill_result_dict.keys(): try: date = bill_result_dict[bill][&#39;date&#39;] date_datetime = time.strptime(date,&#39;%B %d, %Y %I:%M%p&#39;) date_epoch = time.mktime(date_datetime) prob = prob_dict[bill] if prob == .5: #these ones messed up in data download continue pair = [date_epoch,prob,bill] if bill_result_dict[bill][&#39;status&#39;] == &#39;PASS&#39;: date_prob_pairs_passed.append(pair) else: date_prob_pairs_failed.append(pair) except: continue plt.figure(figsize=(20,6)) plt.grid() plt.rcParams[&quot;font.family&quot;] = &quot;Times New Roman&quot; date_prob_pairs_passed = sorted(date_prob_pairs_passed, key=lambda x: x[0]) dates_passed = [datetime.datetime.fromtimestamp(x[0]) for x in date_prob_pairs_passed] probs_passed = [x[1] for x in date_prob_pairs_passed] plt.plot(dates_passed, probs_passed,&#39;g.&#39;,markersize = 5,alpha = .7) date_prob_pairs_failed = sorted(date_prob_pairs_failed, key=lambda x: x[0]) dates_failed = [datetime.datetime.fromtimestamp(x[0]) for x in date_prob_pairs_failed] probs_failed = [x[1] for x in date_prob_pairs_failed] plt.plot(dates_failed, probs_failed, &#39;r.&#39;, markersize = 5,alpha = .5) plt.plot(quality_dates, accuracies,&#39;bo&#39;) plt.plot(quality_dates, accuracies,&#39;b&#39;,linewidth=1) plt.ylabel(&#39;Estimated Probability Taking the Action is in the Public Interest n&amp; nAgreement of Institutional and Epistemic Decisions n over last 6 months&#39;,fontsize=13) plt.xlabel(&#39;Date of Vote&#39;,fontsize=13) plt.title(&#39;U.S. &#39; + chamber + &#39; Epistemic Agreement Plot with Voters as Party Representitives n&#39;,fontsize=18) if chamber == chambers[0]: plt.legend([&#39;Vote Passed&#39;,&#39;Vote Failed&#39;,&#39; nDecimal-Percent Agreement Of Epistemic and Institutional Decisions over last 6 months n&#39; + r&#39;$ frac{(green&gt;.5+red&lt;.5)}{(green&gt;.5+red&lt;.5) + (green&lt;.5+red&gt;.5)}$&#39;], loc=(.255,-.5),fontsize=14) . . The vertical position of each blue dot represents the estimated competence of a chamber of Congress in representing the public interest over the preceding six months. Each green/red dot represents an action voted on by a chamber of congress; its color indicates whether or not the action was taken, and its vertical position is the estimated probability taking it was in the public interest. By my assumed definition of institutional competence, a perfectly competent institution would have all green dots above .5 vertically and all red dots below .5 vertically, indicating that it always made the decision most likely to be in the public interest given the available evidence. . The competencies of the House and the Senate have decayed dramatically over the last generation. The decay reflects the transition of our political parties from trustworthy to untrustworthy in the eyes of the public; once the parties crossed the competence threshold of $.5$, they became more likely to vote against the public interest than for it. Across the threshold, individual representatives are less reliable than a coin flip; a coin with Yea on one side and Nay on the other is more likely to vote in the public interest than a representative of the public. In fact, across the threshold, each vote by a representative for an option becomes evidence against it. . Because both political parties presently have a competence below $.5$, unanimous majority decisions are estimated as having an approximately $0 %$ chance of being in the public interest. For party line votes, because the Republican party is presently less competent than the Democratic party, the Democratic choice is seen as being more likely than the Republican choice to be in the public interest; the Republican votes provide more evidence for the Democratic choice than the Democratic votes do for the Republican choice. . Because congressional voting data only started to be digitized in 1989 and Gallup only started to poll party images in 1993, there is no convenient way for me to compare the trajectories observed here to earlier trends. . Footnotes . 1 . $x=1$ will be the option most likely to be correct if $ prod_{i=1}^{N}( frac{p_i}{1-p_i})^{-xv_i} &lt; 1$, or, applying basic logarithm rules, if $ sum_{i=1}^N v_i w_i &gt; 0$ where $w_i=ln( frac{p_i}{1-p_i})$. This is recognizable as the weighted majority decision rule with optimal weights. .",
            "url": "https://dankee-yoodle.github.io/iob/2020/04/20/A-Naive-Bayes-Framework-for-Estimating-the-Competence-of-an-Institution-Applied-to-the-United-States-Congress.html",
            "relUrl": "/2020/04/20/A-Naive-Bayes-Framework-for-Estimating-the-Competence-of-an-Institution-Applied-to-the-United-States-Congress.html",
            "date": " • Apr 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://dankee-yoodle.github.io/iob/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dankee-yoodle.github.io/iob/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}